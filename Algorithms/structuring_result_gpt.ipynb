{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuqy15hAXZWv",
        "outputId": "34bab9b8-f019-4c8e-ae50-543e3c5c670f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standardize result"
      ],
      "metadata": {
        "id": "MqCCrzg6bnnR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhnmOuQ9Vrce"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import os\n",
        "\n",
        "def map_json_to_format(data):\n",
        "    mapping = {\n",
        "      # 0 - Primeira Habilitação\n",
        "      \"primeira_habilitação\": 0,\n",
        "      \"primeira_habilitacao\": 0,\n",
        "      \"primeira habilitação\": 0,\n",
        "      \"pela_primeira_habilitação\": 0,\n",
        "      \"1ª_habilitação\": 0,\n",
        "      \"data_primeira_habilitação\": 0,\n",
        "\n",
        "      # 1 - Categoria\n",
        "      \"categoria\": 1,\n",
        "      \"categoría\": 1,\n",
        "\n",
        "      # 2 - CPF\n",
        "      \"cpf\": 2,\n",
        "      \"CPF\": 2,\n",
        "\n",
        "      # 3 - Data de Nascimento\n",
        "      \"data_de_nascimento\": 3,\n",
        "      \"data_nascimento\": 3,\n",
        "      \"data de nascimento\": 3,\n",
        "      \"data_nascimento_2\": 3,\n",
        "      \"data_de_nascimento_2\": 3,\n",
        "      \"data_de_nascimento_duplicada\": 3,\n",
        "      \"data_de_nascimento_repetida\": 3,\n",
        "      \"data_nascimento_repete\": 3,\n",
        "      \"data_nascimento_repetida\": 3,\n",
        "      \"data_nascimento_rep\": 3,\n",
        "      \"data_nascimento_secundária\": 3,\n",
        "      \"data_nascimento_acc\": 3,\n",
        "      \"data_nascimento_registro\": 3,\n",
        "      \"data de nascimento (filiação)\": 3,\n",
        "\n",
        "      # 4 - Documento de Identidade/Órgão Emissor/UF\n",
        "      \"documento_de_identidade\": 4,\n",
        "      \"documento_identidade\": 4,\n",
        "      \"documento de identidade\": 4,\n",
        "      \"doc_identidade\": 4,\n",
        "      \"doc. identidade\": 4,\n",
        "      \"órgão_emissor\": 4,\n",
        "      \"orgao_emissor\": 4,\n",
        "      \"organização_emissor\": 4,\n",
        "      \"órgão emissor\": 4,\n",
        "      \"orgão_emissor\": 4,\n",
        "      \"orgão emissor\": 4,\n",
        "      \"órgao_emissor\": 4,\n",
        "      \"org. emissor\": 4,\n",
        "      \"UF\": 4,\n",
        "      \"uf\": 4,\n",
        "\n",
        "      # 5 - Filiação\n",
        "      \"filiação\": 5,\n",
        "      \"filiacao\": 5,\n",
        "      \"afiliação\": 5,\n",
        "      \"filacao\": 5,\n",
        "\n",
        "      # 6 - Número do Registro\n",
        "      \"número_do_registro\": 6,\n",
        "      \"número_registro\": 6,\n",
        "      \"n_registro\": 6,\n",
        "      \"número do registro\": 6,\n",
        "      \"numero_do_registro\": 6,\n",
        "      \"numero_registro\": 6,\n",
        "\n",
        "      # 7 - Nome\n",
        "      \"nome\": 7,\n",
        "\n",
        "      # 8 - Validade\n",
        "      \"validade\": 8,\n",
        "\n",
        "      # 9 - Número Válido\n",
        "      \"número_válido\": 9,\n",
        "      \"número_valido\": 9,\n",
        "      \"numero_valido\": 9,\n",
        "      \"numero_valido_lateral\": 9,\n",
        "      \"número_válido_lateral\": 9,\n",
        "      \"numero_valido_vertical\": 9,\n",
        "      \"número_válido_vertical\": 9,\n",
        "\n",
        "      # 10 - Permissão\n",
        "      \"permissão\": 10,\n",
        "      \"permissao\": 10,\n",
        "\n",
        "      # 11 - ACC\n",
        "      \"ACC\": 11,\n",
        "      \"acc\": 11,\n",
        "      \"accent\": 11,\n",
        "\n",
        "      # Outras datas\n",
        "      \"data_cadastro\": 12,\n",
        "      \"data_de_biometria\": 12,\n",
        "      \"data_de_registro\": 12,\n",
        "      \"data_documento\": 12\n",
        "  }\n",
        "\n",
        "\n",
        "    result_dict = {}\n",
        "\n",
        "    for key, value in mapping.items():\n",
        "        if key in data and data[key]:\n",
        "            if isinstance(data[key], list):\n",
        "                if all(isinstance(item, dict) for item in data[key]):\n",
        "                    data[key] = ' '.join(\n",
        "                        re.sub(r'\\\\', '', value) for obj in data[key] for value in obj.values()\n",
        "                    )\n",
        "                else:\n",
        "                    data[key] = ' '.join(\n",
        "                        item.replace('\\\\', '') for item in data[key]\n",
        "                    )\n",
        "            elif isinstance(data[key], dict):\n",
        "                data[key] = ' '.join(\n",
        "                    re.sub(r'\\\\', '', value) for value in data[key].values()\n",
        "                )\n",
        "            else:\n",
        "                data[key] = data[key].replace('\\\\', '')\n",
        "            print(data[key])\n",
        "            if key in  {'filiação', 'filiacao', 'afiliação', 'filacao'} :\n",
        "              if isinstance(data[key], list):\n",
        "                if all(isinstance(item, dict) for item in data[key]):\n",
        "                    data[key] = ' '.join(\n",
        "                        re.sub(r'[\\n,;\\\\]', '', value) for obj in data[key] for value in obj.values()\n",
        "                    )\n",
        "                else:\n",
        "                    data[key] = ' '.join(\n",
        "                        item.replace('\\n', ' ').replace(',', '').replace(';', '').replace('\\\\', '')\n",
        "                        for item in data[key]\n",
        "                    )\n",
        "              elif isinstance(data[key], dict):\n",
        "                  data[key] = ' '.join(\n",
        "                      re.sub(r'[\\n,;\\\\]', '', value) for value in data[key].values()\n",
        "                  )\n",
        "              else:\n",
        "                  data[key] = data[key].replace('\\n', ' ').replace(',', '').replace(';', '').replace('\\\\', '').replace('PAI:', '').replace('MÃE:', '')\n",
        "            if value in result_dict:\n",
        "                result_dict[value] += f\" {data[key]}\"\n",
        "            else:\n",
        "                result_dict[value] = f'{data[key]}'\n",
        "\n",
        "    result = [f'{key} \"{value}\"' for key, value in result_dict.items()]\n",
        "    print(result)\n",
        "    return result\n",
        "\n",
        "\n",
        "def extract_json_from_txt(txt_content):\n",
        "    json_match = re.search(r'\\{.*\\}', txt_content, re.DOTALL)\n",
        "\n",
        "    if json_match:\n",
        "        cleaned_json_str = json_match.group().replace('\\\\', '\\\\\\\\')\n",
        "        return json.loads(cleaned_json_str)\n",
        "    else:\n",
        "        print(\"No JSON blocks found in file\")\n",
        "\n",
        "def process_and_save_txt_file(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
        "        txt_content = file.read()\n",
        "\n",
        "    data = extract_json_from_txt(txt_content)\n",
        "\n",
        "    if (data):\n",
        "      formatted_data = map_json_to_format(data)\n",
        "\n",
        "      output_dir = os.path.dirname(output_file_path)\n",
        "      if not os.path.exists(output_dir):\n",
        "          os.makedirs(output_dir)\n",
        "\n",
        "      with open(output_file_path, 'w', encoding='utf-8') as file:\n",
        "          for line in formatted_data:\n",
        "              file.write(line + '\\n')\n",
        "\n",
        "# Path to input (gpt return) and output (formatted return) folders\n",
        "input_base_dir = '/content/drive/MyDrive/GPT/resultados_gpt_mini'\n",
        "output_base_dir = '/content/drive/MyDrive/GPT/resultados_gpt_mini_formatado'\n",
        "\n",
        "# Traverse all subfolders of the input directory\n",
        "for folder_name in os.listdir(input_base_dir):\n",
        "    input_folder_path = os.path.join(input_base_dir, folder_name)\n",
        "\n",
        "    if os.path.isdir(input_folder_path):\n",
        "        input_file_path = os.path.join(input_folder_path, 'hipotese.txt')\n",
        "\n",
        "        if os.path.exists(input_file_path):\n",
        "            output_folder_path = os.path.join(output_base_dir, folder_name)\n",
        "            output_file_path = os.path.join(output_folder_path, 'resultado.txt')\n",
        "\n",
        "            print(input_file_path)\n",
        "            process_and_save_txt_file(input_file_path, output_file_path)\n",
        "\n",
        "        else:\n",
        "            print(f\"File 'hipotese.txt' not found in: {input_folder_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find attributes in results"
      ],
      "metadata": {
        "id": "QENTVPrkbfV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import os\n",
        "\n",
        "# Function to extract the JSON from within the text file\n",
        "def extract_json_from_txt(txt_content):\n",
        "    json_match = re.search(r'\\{.*\\}', txt_content, re.DOTALL)\n",
        "    if json_match:\n",
        "        return json.loads(json_match.group())\n",
        "    else:\n",
        "        raise ValueError(\"Nenhum bloco JSON encontrado no arquivo\")\n",
        "\n",
        "# Function to loop through all txt files and identify attribute names in JSON\n",
        "def find_unique_attributes_in_json(base_dir):\n",
        "    unique_attributes = set()  # Use a set to ensure attributes are unique\n",
        "\n",
        "    # Cycle through all subfolders and files in the base folder\n",
        "    for folder_name in os.listdir(base_dir):\n",
        "        folder_path = os.path.join(base_dir, folder_name)\n",
        "\n",
        "        if os.path.isdir(folder_path):\n",
        "            for file_name in os.listdir(folder_path):\n",
        "                if file_name.endswith('.txt'):\n",
        "                    file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                        txt_content = file.read()\n",
        "\n",
        "                    try:\n",
        "                        # Extract JSON and get attributes (keys)\n",
        "                        data = extract_json_from_txt(txt_content)\n",
        "                        unique_attributes.update(data.keys())\n",
        "                    except ValueError as e:\n",
        "                        print(f\"Error processing file {file_path}: {e}\")\n",
        "\n",
        "    return unique_attributes\n",
        "\n",
        "input_base_dir = '/content/drive/MyDrive/resultados_gpt_mini'\n",
        "\n",
        "# Identify all unique attributes\n",
        "unique_attributes = find_unique_attributes_in_json(input_base_dir)\n",
        "\n",
        "# Display the names of unique attributes found\n",
        "print(\"Unique attributes found in JSON:\")\n",
        "for attribute in sorted(unique_attributes):\n",
        "    print(attribute)\n"
      ],
      "metadata": {
        "id": "aRWA8o3VEr1a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}