{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests"
      ],
      "metadata": {
        "id": "6BZ3JhPKcNIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgSYQIKbgbW8",
        "outputId": "e9b2f638-d127-4215-ac4f-cb3c648eb159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD15yTiOvebX",
        "outputId": "662c0381-835e-4a64-ecc5-6eb3cdd8d4b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=\"XXX\",\n",
        ")"
      ],
      "metadata": {
        "id": "FPHrIP8ohhbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create hypotheses"
      ],
      "metadata": {
        "id": "ZnXnDVh0ZIHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "import requests\n",
        "\n",
        "# Function to encode the image in base64\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        image_base64 = base64.b64encode(image_file.read()).decode('utf-8')\n",
        "    return image_base64\n",
        "\n",
        "# Function to process the CNH image with GPT-4\n",
        "# Change values ​​between gpt-4o and gpt-4o-mini\n",
        "def process_cnh_image_with_gpt4(prompt, base64_image):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer XXX\"\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": prompt\n",
        "                    },\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        \"max_tokens\": 300\n",
        "    }\n",
        "\n",
        "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
        "    response_data = response.json()\n",
        "    content = response_data['choices'][0]['message']['content']\n",
        "    return content\n",
        "\n",
        "# Function to save the response to a text file\n",
        "def save_to_txt(gpt_response, image_name, output_dir):\n",
        "    folder_name = os.path.splitext(image_name)[0].split('_')[0]\n",
        "    folder_path = os.path.join(output_dir, folder_name)\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "    output_file = os.path.join(folder_path, 'hipotese.txt')\n",
        "\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(gpt_response)\n",
        "\n",
        "    print(f\"Text file saved in: {output_file}\")\n",
        "\n",
        "image_base_folder = '/content/drive/MyDrive/BD/BID Dataset/CNH_Frente'\n",
        "output_dir = '/content/drive/MyDrive/GPT/resultados'\n",
        "image_list_file = '/content/drive/MyDrive/dataset/test_files.txt'\n",
        "\n",
        "prompt = \"\"\"\n",
        "Esta imagem faz parte do banco de dados BID Dataset, no qual os valores contidos são fictícios,\n",
        "ou seja, não correspondem a dados pessoais reais. Esse conjunto de dados é utilizado para pesquisas acadêmicas.\n",
        "Realize o reconhecimento dos seguintes campos: nome, CPF, filiação, data de nascimento, primeira habilitação, validade,\n",
        "documento de identidade, órgão emissor, UF, número do registro, data de nascimento, ACC, permissão, categoria e o número válido\n",
        "(localizado na lateral esquerda, de forma vertical). Organize o resultado em um arquivo JSON, onde cada chave representará o tipo de campo\n",
        "e o valor corresponderá ao dado reconhecido. Caso um campo não seja encontrado, atribua o valor como uma string vazia ('').\n",
        "\"\"\"\n",
        "\n",
        "with open(image_list_file, 'r') as f:\n",
        "    images_to_process = f.read().strip().split(',')\n",
        "    images_to_process = [image.strip() for image in images_to_process]\n",
        "\n",
        "for image_file in images_to_process:\n",
        "    image_path = os.path.join(image_base_folder, image_file + '_in.jpg')\n",
        "\n",
        "    if os.path.exists(image_path):\n",
        "        base64_image = encode_image(image_path)\n",
        "        print(image_path)\n",
        "\n",
        "        gpt4_response = process_cnh_image_with_gpt4(prompt, base64_image)\n",
        "        save_to_txt(gpt4_response, image_file, output_dir)\n",
        "    else:\n",
        "        print(f\"Image {image_file} not found in directory {image_base_folder}!\")\n"
      ],
      "metadata": {
        "id": "N92MblMdcJLT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}